{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df931477-2e50-4eba-83ab-7d3b984fd215",
   "metadata": {},
   "source": [
    "# D209 - Data Mining 1 Performance Assessment Task 2\n",
    "Aidan Soares, 012042436, Western Governors University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0deac4-f6ec-4802-9a24-ad3bd04fc1cd",
   "metadata": {},
   "source": [
    "### A1: Research Question\n",
    "For this task, my research question is \"Can I effectively predict customer Tenure via decision trees using the data available?\". I will be using the Churn dataset for this assessment. Tenure is the foundation for sustainable and long-term financial success for telecommunication companies. The longer individuals retain subscription to one company, the more likely it is that they have developped a strong service model, great customer satisfaction rates, and will naturally grow through online user reviews and word-of-mouth recommendations. This growth is ideal for an industry where competition is fierce and each company has to undercut each other via loss leading service packages, as customers can very easily be persuaded in dropping one company for another with a simple phone call. \n",
    "\n",
    "By making predictions of customer tenure through the collected data available, these companies can assess the longevity of their customer relations based on existing features, identifying whether or not current service packages require improvement for customer satistfaction. This will ultimately result in effective resource allocation, dictating exactly when the company may be in danger of customers ending their tenure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a7715-93d1-4a18-95e2-45cdb30d2b8e",
   "metadata": {},
   "source": [
    "### A2: Goal\n",
    "The question I pose is similar in nature to the one used in D208's Task 1. I have attempted to develop a regression model that could accurately establish known and relevant relationships between independant variables and the depandant variable Tenure. Within the multiple linear regression model I created, I found that the resulting analysis did not conform to the assumptions necessary to deem the model acceptable and applicable in a corporate environment. My goal for this assessment is to try again using decision trees this time to build a machine learning model that can help the company predict its customers tenure, allowing them to generate useful insights into variables that are negatively impacting the tenure rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc51f8-72ef-44b1-a3b4-d4ceca0333bc",
   "metadata": {},
   "source": [
    "### B1: Classification Method\n",
    "The classification method I have chosen is a decision tree. This classification method is structured like a tree, consisting of nodes in heirarchal format that classify datapoints and sort them as information is passed down the tree. Each node serves as a test for some attribute such as \"Does the customer have online protection? How many children does the customer have? etc...\", splitting said node into two or more sub-nodes based on homogeny (similarity). The tree will use multiple algorithms to perform these tests recursively until the decision criteria has been met (Chauhan, 2022). From this, the tree will identify the nodes and selected criteria to identify branch pathways that result in an appropriately predicted tenure length to its best ability, this final resulting node is referred to as the leaf node. Using this method, I am aiming to build a model that will be able to assess a customer given their collected data and deduce their estimated tenure, the company can then utilize these predictions for cost-benefit analyses on how to proceed to increase customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a165fb7b-b2d2-432d-a0dd-3cac2413a352",
   "metadata": {},
   "source": [
    "### B2: Decision Tree Assumption\n",
    "The major assumption of decision trees is that it is a non-parametric algorithm, the data can be collected from samples that do not follow specific distributions. This means that the data we are working with for this algorithm is not restricted to any one dimension, the decision tree can deal with linear, non-linear data, categorical data, ordinal data all the same (Datacamp, 2023). Its multidimensional nature of decision trees allow for minimal cleaning in order to start building the model, but it is also able to handle high variety of data with less computational requirements and solid accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16465ae1-7d9e-41ef-90fc-4801273ee2e6",
   "metadata": {},
   "source": [
    "### B3: Packages/Libraries\n",
    "For this assessment I will be using Python. This language was chosen due to its ability to handle a wide variety of data analytical processes, large sets of data, and ease of use for data transformation, cleaning, and visualization. Many python packages are tailored to specific tasks with intuitive naming conventions, giving me efficiency in my analysis.\n",
    "\n",
    "The packages I have chosen to apply for my assessment, as well as their purpose are as follows:\n",
    "- Pandas: for importing my dataset into a dataframe, allows for manipulation of data, columns, datatypes.\n",
    "- NumPy: for conducting mathematical operations and array manipulation.\n",
    "- Matplotlib & Seaborn: packages designed for visualization of distribution as it has multiple chart types.\n",
    "- scikit-learn: provides several tools necessary to conduct my decision tree model. Elaborated on below.\n",
    "- sklearn train_test_split: used to split the dataset between training and testing data. GridSearchCV will be used to identify optimal values for maximizing performance\n",
    "- sklearn DecisionTreeRegressor: used to generate the decision tree.\n",
    "- several sklearn metrics libraries such as: r2_score, accuracy_score, mean_squared_error that are used to evaluate our decision tree algorithm's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f71173c9-ecc8-419b-821f-bc7cc0a7d20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>UID</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "      <th>Item1</th>\n",
       "      <th>Item2</th>\n",
       "      <th>Item3</th>\n",
       "      <th>Item4</th>\n",
       "      <th>Item5</th>\n",
       "      <th>Item6</th>\n",
       "      <th>Item7</th>\n",
       "      <th>Item8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CaseOrder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K409198</td>\n",
       "      <td>aa90260b-4141-4a24-8e36-b04ce1f4f77b</td>\n",
       "      <td>e885b299883d4f9fb18e39c75155d990</td>\n",
       "      <td>Point Baker</td>\n",
       "      <td>AK</td>\n",
       "      <td>Prince of Wales-Hyder</td>\n",
       "      <td>99927</td>\n",
       "      <td>56.25100</td>\n",
       "      <td>-133.37571</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>172.455519</td>\n",
       "      <td>904.536110</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S120509</td>\n",
       "      <td>fb76459f-c047-4a9d-8af9-e0f7d4ac2524</td>\n",
       "      <td>f2de8bef964785f41a2959829830fb8a</td>\n",
       "      <td>West Branch</td>\n",
       "      <td>MI</td>\n",
       "      <td>Ogemaw</td>\n",
       "      <td>48661</td>\n",
       "      <td>44.32893</td>\n",
       "      <td>-84.24080</td>\n",
       "      <td>10446</td>\n",
       "      <td>...</td>\n",
       "      <td>242.632554</td>\n",
       "      <td>800.982766</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K191035</td>\n",
       "      <td>344d114c-3736-4be5-98f7-c72c281e2d35</td>\n",
       "      <td>f1784cfa9f6d92ae816197eb175d3c71</td>\n",
       "      <td>Yamhill</td>\n",
       "      <td>OR</td>\n",
       "      <td>Yamhill</td>\n",
       "      <td>97148</td>\n",
       "      <td>45.35589</td>\n",
       "      <td>-123.24657</td>\n",
       "      <td>3735</td>\n",
       "      <td>...</td>\n",
       "      <td>159.947583</td>\n",
       "      <td>2054.706961</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D90850</td>\n",
       "      <td>abfa2b40-2d43-4994-b15a-989b8c79e311</td>\n",
       "      <td>dc8a365077241bb5cd5ccd305136b05e</td>\n",
       "      <td>Del Mar</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>92014</td>\n",
       "      <td>32.96687</td>\n",
       "      <td>-117.24798</td>\n",
       "      <td>13863</td>\n",
       "      <td>...</td>\n",
       "      <td>119.956840</td>\n",
       "      <td>2164.579412</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K662701</td>\n",
       "      <td>68a861fd-0d20-4e51-a587-8a90407ee574</td>\n",
       "      <td>aabb64a116e83fdc4befc1fbab1663f9</td>\n",
       "      <td>Needville</td>\n",
       "      <td>TX</td>\n",
       "      <td>Fort Bend</td>\n",
       "      <td>77461</td>\n",
       "      <td>29.38012</td>\n",
       "      <td>-95.80673</td>\n",
       "      <td>11352</td>\n",
       "      <td>...</td>\n",
       "      <td>149.948316</td>\n",
       "      <td>271.493436</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Customer_id                           Interaction  \\\n",
       "CaseOrder                                                     \n",
       "1             K409198  aa90260b-4141-4a24-8e36-b04ce1f4f77b   \n",
       "2             S120509  fb76459f-c047-4a9d-8af9-e0f7d4ac2524   \n",
       "3             K191035  344d114c-3736-4be5-98f7-c72c281e2d35   \n",
       "4              D90850  abfa2b40-2d43-4994-b15a-989b8c79e311   \n",
       "5             K662701  68a861fd-0d20-4e51-a587-8a90407ee574   \n",
       "\n",
       "                                        UID         City State  \\\n",
       "CaseOrder                                                        \n",
       "1          e885b299883d4f9fb18e39c75155d990  Point Baker    AK   \n",
       "2          f2de8bef964785f41a2959829830fb8a  West Branch    MI   \n",
       "3          f1784cfa9f6d92ae816197eb175d3c71      Yamhill    OR   \n",
       "4          dc8a365077241bb5cd5ccd305136b05e      Del Mar    CA   \n",
       "5          aabb64a116e83fdc4befc1fbab1663f9    Needville    TX   \n",
       "\n",
       "                          County    Zip       Lat        Lng  Population  ...  \\\n",
       "CaseOrder                                                                 ...   \n",
       "1          Prince of Wales-Hyder  99927  56.25100 -133.37571          38  ...   \n",
       "2                         Ogemaw  48661  44.32893  -84.24080       10446  ...   \n",
       "3                        Yamhill  97148  45.35589 -123.24657        3735  ...   \n",
       "4                      San Diego  92014  32.96687 -117.24798       13863  ...   \n",
       "5                      Fort Bend  77461  29.38012  -95.80673       11352  ...   \n",
       "\n",
       "          MonthlyCharge Bandwidth_GB_Year Item1  Item2  Item3  Item4 Item5  \\\n",
       "CaseOrder                                                                    \n",
       "1            172.455519        904.536110     5      5      5      3     4   \n",
       "2            242.632554        800.982766     3      4      3      3     4   \n",
       "3            159.947583       2054.706961     4      4      2      4     4   \n",
       "4            119.956840       2164.579412     4      4      4      2     5   \n",
       "5            149.948316        271.493436     4      4      4      3     4   \n",
       "\n",
       "          Item6 Item7  Item8  \n",
       "CaseOrder                     \n",
       "1             4     3      4  \n",
       "2             3     4      4  \n",
       "3             3     3      3  \n",
       "4             4     3      3  \n",
       "5             4     4      5  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "#importing dataset into a dataframe\n",
    "df = pd.read_csv('churn_clean.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff8a00-841d-4b0e-86c6-6a33618babd6",
   "metadata": {},
   "source": [
    "### C1: Data Preprocessing\n",
    "While I stated that decision tree algorithms are ones that can deal with a high dimensionality of data, evaluation still needs to be done on numeric data even if my independant variable is categorical. Thus, to reiterate from my previous task's paper; categorical data will be re-expressed ordinally as 1 and 0 so that it may be used within my analysis. For binary categorical variables, I will be re-expressing their 'yes' and 'no' answers as 1 and 0. For categorical variables with more than 2 responses, I will preform one-hot encoding to generate dummy columns in the 1, 0 answer format, ensuring that I drop the first column to prevent any potential problems with multicollinearity from arising. I will largely be re-using the independant variables that remained from my D208 task 1 paper in my final multiple linear regression model as the variables isolated during my analysis demonstrated the most promise in a statistically significant relationship to my dependant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60d6d7-d01b-4bd1-8ffb-a11e3a1a09d9",
   "metadata": {},
   "source": [
    "### C2: Dataset Variables\n",
    "| Variable Name | Numeric/Categorical | Dependant/Independant |\n",
    "| :- | :- | :- |\n",
    "| Tenure | Numeric | *Dependant* |\n",
    "| Children | Numeric | Independant |\n",
    "| Age | Numeric | Independant |\n",
    "| Outage | Numeric | Independant |\n",
    "| Monthly Charge | Numeric | Independant |\n",
    "| Bandwidth | Numeric | Independant |\n",
    "| Contract | Categorical | Independant |\n",
    "| Internet Service | Categorical | Independant |\n",
    "| Online Security | Categorical | Independant |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b1fd4-7cb2-41b8-bd84-62962ee8b3b5",
   "metadata": {},
   "source": [
    "### C3: Analysis Steps\n",
    "First and foremost, as I do with all my assessments, I will first utilize a .info() and .duplicated() function to identify any null values/duplicates that need to be imputed or removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "da954e23-c602-44e8-8a4b-bc0d53162501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Customer_id           10000 non-null  object \n",
      " 1   Interaction           10000 non-null  object \n",
      " 2   UID                   10000 non-null  object \n",
      " 3   City                  10000 non-null  object \n",
      " 4   State                 10000 non-null  object \n",
      " 5   County                10000 non-null  object \n",
      " 6   Zip                   10000 non-null  int64  \n",
      " 7   Lat                   10000 non-null  float64\n",
      " 8   Lng                   10000 non-null  float64\n",
      " 9   Population            10000 non-null  int64  \n",
      " 10  Area                  10000 non-null  object \n",
      " 11  TimeZone              10000 non-null  object \n",
      " 12  Job                   10000 non-null  object \n",
      " 13  Children              10000 non-null  int64  \n",
      " 14  Age                   10000 non-null  int64  \n",
      " 15  Income                10000 non-null  float64\n",
      " 16  Marital               10000 non-null  object \n",
      " 17  Gender                10000 non-null  object \n",
      " 18  Churn                 10000 non-null  object \n",
      " 19  Outage_sec_perweek    10000 non-null  float64\n",
      " 20  Email                 10000 non-null  int64  \n",
      " 21  Contacts              10000 non-null  int64  \n",
      " 22  Yearly_equip_failure  10000 non-null  int64  \n",
      " 23  Techie                10000 non-null  object \n",
      " 24  Contract              10000 non-null  object \n",
      " 25  Port_modem            10000 non-null  object \n",
      " 26  Tablet                10000 non-null  object \n",
      " 27  InternetService       10000 non-null  object \n",
      " 28  Phone                 10000 non-null  object \n",
      " 29  Multiple              10000 non-null  object \n",
      " 30  OnlineSecurity        10000 non-null  object \n",
      " 31  OnlineBackup          10000 non-null  object \n",
      " 32  DeviceProtection      10000 non-null  object \n",
      " 33  TechSupport           10000 non-null  object \n",
      " 34  StreamingTV           10000 non-null  object \n",
      " 35  StreamingMovies       10000 non-null  object \n",
      " 36  PaperlessBilling      10000 non-null  object \n",
      " 37  PaymentMethod         10000 non-null  object \n",
      " 38  Tenure                10000 non-null  float64\n",
      " 39  MonthlyCharge         10000 non-null  float64\n",
      " 40  Bandwidth_GB_Year     10000 non-null  float64\n",
      " 41  Item1                 10000 non-null  int64  \n",
      " 42  Item2                 10000 non-null  int64  \n",
      " 43  Item3                 10000 non-null  int64  \n",
      " 44  Item4                 10000 non-null  int64  \n",
      " 45  Item5                 10000 non-null  int64  \n",
      " 46  Item6                 10000 non-null  int64  \n",
      " 47  Item7                 10000 non-null  int64  \n",
      " 48  Item8                 10000 non-null  int64  \n",
      "dtypes: float64(7), int64(15), object(27)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "False    10000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for null values in dataframe\n",
    "print(df.info())\n",
    "\n",
    "#checking for duplicate values in dataframe\n",
    "print(df.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7dea39-abaf-4293-83d8-091ccbfeb9d3",
   "metadata": {},
   "source": [
    "As there are no null values or duplicates within my dataset, no imputations will be required for any entry.\n",
    "\n",
    "Next will come the re-expression of all my categorical variables into numeric data: Converting binary answers into 1 and 0 format, and converting multi-categorical variable data into dummy variables, making sure to drop the first column to prevent any issues with perfect multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e376b60e-5a3a-4faa-8201-445a0ae81805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outage_sec_perweek</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two Year</th>\n",
       "      <th>InternetService_Fiber Optic</th>\n",
       "      <th>InternetService_None</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CaseOrder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.795513</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>7.978323</td>\n",
       "      <td>1</td>\n",
       "      <td>172.455519</td>\n",
       "      <td>904.536110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.156681</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11.699080</td>\n",
       "      <td>1</td>\n",
       "      <td>242.632554</td>\n",
       "      <td>800.982766</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.754144</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>10.752800</td>\n",
       "      <td>0</td>\n",
       "      <td>159.947583</td>\n",
       "      <td>2054.706961</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.087227</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>14.913540</td>\n",
       "      <td>1</td>\n",
       "      <td>119.956840</td>\n",
       "      <td>2164.579412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.670972</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8.147417</td>\n",
       "      <td>0</td>\n",
       "      <td>149.948316</td>\n",
       "      <td>271.493436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tenure  Children  Age  Outage_sec_perweek  OnlineSecurity  \\\n",
       "CaseOrder                                                                 \n",
       "1           6.795513         0   68            7.978323               1   \n",
       "2           1.156681         1   27           11.699080               1   \n",
       "3          15.754144         4   50           10.752800               0   \n",
       "4          17.087227         1   48           14.913540               1   \n",
       "5           1.670972         0   83            8.147417               0   \n",
       "\n",
       "           MonthlyCharge  Bandwidth_GB_Year  Contract_One year  \\\n",
       "CaseOrder                                                        \n",
       "1             172.455519         904.536110                  1   \n",
       "2             242.632554         800.982766                  0   \n",
       "3             159.947583        2054.706961                  0   \n",
       "4             119.956840        2164.579412                  0   \n",
       "5             149.948316         271.493436                  0   \n",
       "\n",
       "           Contract_Two Year  InternetService_Fiber Optic  \\\n",
       "CaseOrder                                                   \n",
       "1                          0                            1   \n",
       "2                          0                            1   \n",
       "3                          1                            0   \n",
       "4                          1                            0   \n",
       "5                          0                            1   \n",
       "\n",
       "           InternetService_None  \n",
       "CaseOrder                        \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "5                             0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe to store data from C2\n",
    "clean_df = df[[\"Tenure\", \"Children\", \"Age\", \"Outage_sec_perweek\", \"Contract\", \"InternetService\", \"MonthlyCharge\", \"Bandwidth_GB_Year\"]]\n",
    "\n",
    "#inserting online security column after re-expressing the data ordinally\n",
    "clean_df.insert(6, \"OnlineSecurity\", df[\"OnlineSecurity\"].replace({\"Yes\": 1, \"No\": 0}))\n",
    "\n",
    "#creating dummy variables, dropping the first column from each\n",
    "clean_df = pd.get_dummies(clean_df, columns=[\"Contract\", \"InternetService\"], drop_first=True)\n",
    "\n",
    "#printing dataframe to see if information has been updated\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4f162-9334-4593-b513-9e6b51108808",
   "metadata": {},
   "source": [
    "Note that due to the multidimensional ability for decision tree algorithms to handle and manage large scale data, none of the data needs to by scaled or normalized like in other assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c8b9a5da-9663-42f7-b661-6c52674bfb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean        34.526188\n",
       "std         26.443063\n",
       "min          1.000259\n",
       "25%          7.917694\n",
       "50%         35.430507\n",
       "75%         61.479795\n",
       "max         71.999280\n",
       "Name: Tenure, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing summary statisics for the dependant variable Tenure to view maximum values for later assessment of mse/rmse\n",
    "df[\"Tenure\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50adc1f2-1470-4582-a821-b7f5f2977357",
   "metadata": {},
   "source": [
    "### C4: Cleaned Dataset\n",
    "The below is the code for the cleaned dataset, outputted to a csv and submitted alongside my notebook, test/training data, and panopto video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "485f8de7-914c-46f6-be43-80b261a5f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the dataset to csv file\n",
    "clean_df.to_csv('dectree_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38318a3c-5e05-4d20-bedd-c306d72c2799",
   "metadata": {},
   "source": [
    "### D1: Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a31a96b3-77bf-4bb9-8f62-cdc39a21eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "(2000, 10)\n",
      "(8000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "#splitting data from my cleaned dataframe into training and testing data\n",
    "X = clean_df.drop(columns=[\"Tenure\"])\n",
    "y = clean_df[\"Tenure\"]\n",
    "\n",
    "#splitting the data into training and testing sets, with a 80%train, 20% test split, \n",
    "#using the random state 1 to maintain the exact split across multiple runs of this notebook (Boorman, n.d.)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096cf2f0-5c63-454b-aa0a-ded50e5b02e5",
   "metadata": {},
   "source": [
    "From the above, we can see that the data has been split at 80/20, with 8000 entries for each training set, and 2000 entries for each testing set. The X variable correctly demonstrates the 10 independant variables chosen for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "94441748-8226-44f0-9915-4cf69dab7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting each set of training/testing data to csv\n",
    "X_train.to_csv('t2_X_train.csv', index=False)\n",
    "X_test.to_csv('t2_X_test.csv', index=False)\n",
    "y_train.to_csv('t2_y_train.csv', index=False)\n",
    "y_test.to_csv('t2_y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c92e2a-caaf-4231-9c65-cd16a4cc54e5",
   "metadata": {},
   "source": [
    "### D2: Output/Intermediate Calculations\n",
    "As stated above, the decision tree regression model learns from the training data fed to it. Once I fit the training data I generated above, the model maps and develops node tests based on the known variables, relationships, and outcomes present within the data I have at my disposal. In assessing my decision tree, I will print the resulting tree's mean squared error (MSE), the average sqaured distance between my model's predicted and actual target values. The lower my model's MSE the higher the indicated performance, as this demonstrates a closer estimate to my actual result. \n",
    "\n",
    "The amount of levels a decision tree makes in creating nodes does impact the processing speed and resulting MSE, as trees using default settings can overfit and try to adapt to noise within the data, resulting in poor performance and inability for generalized use. To combat this, I will be utilizing hyperparameter tuning tools such as GridSearchCV to identify the most optimal parameters to apply for my model such as max depth of the tree and the minimum samples needed for a leaf node. The steps for this tuning can be found in the cell below via commented notes but as a general overview: I start by creating a basic decision tree regressor model and an array of numbers for assessment of ideal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d6f2144a-8618-49bf-a74a-de70e2335da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=9, min_samples_leaf=5, random_state=2)\n"
     ]
    }
   ],
   "source": [
    "#creating dt variable to store the original model, using all default parameters to see how the model performs\n",
    "#though I am using a random_state of 2 to maintain the shape of my decision tree across all my notebook runs\n",
    "dt = DecisionTreeRegressor(random_state = 2)\n",
    "\n",
    "#creating a dictionary of arrays for assessment of ideal parameters \n",
    "param_list = {\n",
    "    'max_depth': range(1, 10),\n",
    "    'min_samples_leaf': range(1,30),\n",
    "}\n",
    "\n",
    "#utilizing the GridSearchCV function, using the determination of ideal score set to R squared value (Saini, 2020)\n",
    "grid = GridSearchCV(estimator = dt, param_grid = param_list, scoring = 'r2', cv=10, n_jobs=-1)\n",
    "\n",
    "#fitting my training data to the optimal parameter grid\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#printing the best parameters from my gridsearch\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f854e7-ca30-44a0-860a-ee188ef02eb5",
   "metadata": {},
   "source": [
    "Thus, the ideal paramters for this decision tree are a max depth of 9, minimum samples required for a leaf is 5, and of course my assigned random state of 2 to retain the shape across multiple runs of my notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "542462ad-8eba-4aba-a466-1b611af3137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for the model is: 2.9003243317362446\n",
      "The root mean squared error for the model is: 1.7030338610069515\n",
      "R-squared value for test data against ideal decision tree model: 0.9958806522197612\n"
     ]
    }
   ],
   "source": [
    "#creating my ideal decision tree regressor model using the parameters found from my grid search\n",
    "ideal_dt = grid.best_estimator_\n",
    "\n",
    "#creating predictor for test set\n",
    "y_pred = ideal_dt.predict(X_test)\n",
    "\n",
    "#calculating and printing the mse/rmse value\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**(1/2)\n",
    "print(\"The mean squared error for the model is: \" + str(mse))\n",
    "print(\"The root mean squared error for the model is: \" + str(rmse))\n",
    "\n",
    "#printing the r-squared value of my test data fitted against my ideal model\n",
    "rsq = r2_score(y_test, y_pred)\n",
    "print(\"R-squared value for test data against ideal decision tree model: \" + str(rsq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5717882-9e3c-4f28-b1a6-78c4a02512b4",
   "metadata": {},
   "source": [
    "The last thing I would like to do even though it is not necessary for my research question is identify which variables are being weighted the heaviest in my model's performance. I will do so using the feature_importances_ function learned from a tutorial video made by Ryan Nolan (Nolan, 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6a883e06-9519-4b0a-9c01-ba20edc28e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outage_sec_perweek</th>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <td>0.003854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "      <td>0.990287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract_One year</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract_Two Year</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternetService_Fiber Optic</th>\n",
       "      <td>0.002467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternetService_None</th>\n",
       "      <td>0.002693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "Children                     0.000182\n",
       "Age                          0.000479\n",
       "Outage_sec_perweek           0.000018\n",
       "OnlineSecurity               0.000018\n",
       "MonthlyCharge                0.003854\n",
       "Bandwidth_GB_Year            0.990287\n",
       "Contract_One year            0.000002\n",
       "Contract_Two Year            0.000000\n",
       "InternetService_Fiber Optic  0.002467\n",
       "InternetService_None         0.002693"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating and storing the array for my feature weighting \n",
    "features = pd.DataFrame(ideal_dt.feature_importances_, index = X.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037bd428-cf10-44de-b2ac-a912dbe9fe17",
   "metadata": {},
   "source": [
    "As we can see from the above, the Bandwidth column is the only feature that demonstrates a significant impact on the determination of Tenure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca51e8-62a6-41d0-9b7b-57719bda1c07",
   "metadata": {},
   "source": [
    "### D3: Code\n",
    "All code used to perform prediction analysis can be found within section D2 above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a75f3-a68c-4163-acf0-cdc884b935e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### E1: Accuracy & Mean Squared Error\n",
    "Using the calculated ideal parameters of optimal maximum nodes of 9, and minimum sample leaf size of 5, the testing set's mean squared error (MSE) was determined to be 2.9. The value represents the square of the deviance magnitude from the predicted unit's true accuracy. As a better idea of what this value means for our model, the root of the mean squared error (RMSE) was determined to be 1.7, and this represents a standard error of 1.7 months for a customer's tenure. For the context of our assessment here, this is a very low value given that tenure can range from 1 month to 72 months. Overall, the model demonstrates a strong ability to predict a customer's total tenure within 1 to 2 months of accuracy. Ultimately, I cannot say for certain if this RMSE is an ideal low value as I lack the domain knowledge to ascertain its validity in the telecommunications industry but for my assessment I believe this is an appropriate result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e954d0-a2b9-42a7-afa6-2dbc94027fe2",
   "metadata": {},
   "source": [
    "### E2: Results\n",
    "In regards to the r-squared value of my decision tree regression model, I calculated a result of 0.995. This value demonstrates that my decision tree model can explain approximately 99.5% of the variance of my target variable. Meaning that the model above can very accurately predict Tenure's variablility. This is further supported by the RMSE value determined being very low, as such, it is strongly indicated that my decision tree model is useful in predicting a customer's tenure. However, no model is perfect, and it is possible that this one has a hidden failure through potential overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba92e5-d7ed-4d83-b0e7-49dab54e6611",
   "metadata": {},
   "source": [
    "### E3: Limitation\n",
    "As stated above, it is possible that my decision tree model suffers from overfitting. Overfitting implies that the model was trained so effectively through the training data that it is being influenced by noise and specific patterns within the training data, teaching it to only able to draw predictions on this data instead of anything new or unknown. This means that while my model is very good at predicting the target variable, it can only do so on my current dataset and is unable to draw real relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fa17b-7feb-446d-a62b-ad21b4e4c92a",
   "metadata": {},
   "source": [
    "### E4: Recommendations\n",
    "It was mentioned above that there is a possibility that the decision tree regression model may have overfit to the data currently available. This means that the model has gotten extremely good at assessing the customer's likely tenure rate for our telecommunications company. Thus, I can justifyable say that this model would be appropriate for deployment in assessing current metrics of customer Tenure of the current subscribers, allowing for management to identify very accurately the moments in which a customer may require additional service offerings to tempt them to remain a subscriber.\n",
    "\n",
    "However, overfitting comes with the consequence of having difficulty adapting to new or unknown data because it is only really good at assessing *currently available data*. As such, while it is perfectly suitable for assessing current customer churn rates, what if the telecom corporation would like to assess potential tenure rates for new clientele. Say for example, the company would like to target an entirely new market base, a new demographic, or maybe aim to poach customers from another telecom company. They are likely then looking to identify the likely revenue output to weigh against the cost of customer acquisition to establish forecasted budgets and determine feasability. This model may not be applicable for that because it only demonstrates predictive accuracy on the customer data available *within* the company, customers who may have an entirely different mindset, values, or appeal to the brand. I would strongly recommend that before this model can be used for external assessmnet, it has to be validated against either industry standards, or if possible, another company's dataset. That way, the company can be certain if this model will be applicable to new unknown data, rather than just the dataset it has been given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2059e2-d9e7-4752-aadf-c7258a2666af",
   "metadata": {},
   "source": [
    "### F: Panopto\n",
    "My panopto video can be found here: https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=103af793-6bcf-4c31-ad05-b1600177b8fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce34b5c-4605-40e4-9ca7-679ea0b631c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### G: Code Sources\n",
    "Boorman, George. (n.d.). *Supervised Learning with scikit-learn [MOOC].* Datacamp. https://app.datacamp.com/learn/courses/supervised-learning-with-scikit-learn\n",
    "\n",
    "Saini, Bhanwar. (2020, September 29). *Hyperparameter Tuning of Decision Tree Classifier Using GridSearchCV*. PlainEnglish. https://plainenglish.io/blog/hyperparameter-tuning-of-decision-tree-classifier-using-gridsearchcv-2a6ebcaffeda\n",
    "\n",
    "Nolan, Ryan. (2023, August 17). *How to Build Your First Decision Tree in Python (scikit-learn)* Youtube. https://www.youtube.com/watch?v=YkYpGhsCx4c&t=444s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be805b38-b8b1-4500-a512-ee1e213878d4",
   "metadata": {},
   "source": [
    "### H: Sources\n",
    "Chauhan, Nagesh Singh. (2022, February 9). *Decision Tree Algorithm, Explained*. KDNuggets. https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html\n",
    "\n",
    "Datacamp. (2023, February). *Decision Tree Classification in Python Tutorial*. Datacamp. https://www.datacamp.com/tutorial/decision-tree-classification-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
